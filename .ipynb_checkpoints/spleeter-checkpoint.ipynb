{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wavio'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f63c645960f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwavio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastICA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wavio'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import wavio\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the wav file and convert to monoraul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, audio = wavfile.read(\"No Suprises.wav\")\n",
    "\n",
    "# try:\n",
    "#     audio = np.mean(audio, axis=1)\n",
    "# except:\n",
    "#     print(\"mean function passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = audio.shape[0]\n",
    "L = N / rate\n",
    "\n",
    "print(f'Audio length: {L:.2f} seconds')\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(np.arange(N) / rate, audio)\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('Amplitude [unknown]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the spectrogram of the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1024\n",
    "freqs, times, mixed_spectro = signal.spectrogram(np.mean(audio, axis=1), fs=rate, window='hanning',nperseg=1024, noverlap=M - 100, scaling='spectrum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some data normalization so that spectrogram looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_spectro = np.log10( mixed_spectro + 1)\n",
    "mixed_spectro = ( mixed_spectro - np.min( mixed_spectro))/np.ptp( mixed_spectro) \n",
    "mixed_spectro = 255 *  mixed_spectro\n",
    "mixed_spectro =  mixed_spectro.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 7.5))\n",
    "plt.imshow(mixed_spectro,aspect='auto')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_ylabel('Frequency [kHz]')\n",
    "ax.set_xlabel('Time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use spleeter to seperate the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spleeter.separator import Separator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Using embedded configuration... stems can be 2 - 5 (number of instruments in network)\n",
    "separator = Separator('spleeter:5stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the separation\n",
    "prediction = separator.separate(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for instrument in prediction:\n",
    "    \n",
    "    N = prediction[instrument].shape[0]\n",
    "    L = N / rate\n",
    "    \n",
    "    f,ax = plt.subplots()\n",
    "    ax.set_title(instrument)\n",
    "    ax.plot(np.arange(N)/rate,prediction[instrument])\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instrument in prediction:\n",
    "    freqs, times, instrument_spectro = signal.spectrogram(np.mean(prediction[instrument],axis=1), fs=rate, window='hanning',nperseg=1024, noverlap=M - 100, scaling='spectrum')\n",
    "    instrument_spectro = np.log10( instrument_spectro + 1)\n",
    "    instrument_spectro = ( instrument_spectro - np.min( instrument_spectro))/np.ptp( instrument_spectro) \n",
    "    instrument_spectro = 255 *  instrument_spectro\n",
    "    instrument_spectro =  instrument_spectro.astype(np.uint8)\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(15, 7.5))\n",
    "    plt.imshow(instrument_spectro,aspect='auto')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(instrument)\n",
    "    ax.set_ylabel('Frequency [kHz]')\n",
    "    ax.set_xlabel('Time [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wavio\n",
    "\n",
    "rate = 44100\n",
    "\n",
    "for instrument in prediction:\n",
    "    print(\"Saving\",instrument)\n",
    "    \n",
    "    name = \"SpleeterOutputs/\" + instrument +\".wav\"\n",
    "    \n",
    "    print(\"Saving:\",name)\n",
    "\n",
    "    wavio.write(name, prediction[instrument], rate, sampwidth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
